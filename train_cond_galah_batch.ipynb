{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./nf/\")\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch import nn\n",
    "from torch import distributions\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from torch.distributions import (\n",
    "    Normal,\n",
    "    MultivariateNormal,\n",
    "    Uniform,\n",
    "    TransformedDistribution,\n",
    "    SigmoidTransform,\n",
    ")\n",
    "\n",
    "from nf.nets import MLP\n",
    "from nf.flows import NormalizingFlow, NormalizingFlowModel, Invertible1x1Conv, ActNorm\n",
    "from nf.spline_flows import NSF_CL\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the cpu...\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "elif device.type == \"cpu\":\n",
    "    print('Using the cpu...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(284, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose data here\n",
    "spectra = np.loadtxt(\"./data/galah_batch_Xtrain.csv\")\n",
    "\n",
    "spectra = spectra.T\n",
    "spectra = torch.Tensor(spectra)\n",
    "dim = spectra.shape[-1]\n",
    "print(dim)\n",
    "\n",
    "labels = np.loadtxt(\"./data/galah_batch_ytrain.csv\")\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> build smalled dimensionality :))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284, 3)\n",
      "torch.Size([284, 3])\n",
      "x shape torch.Size([284, 10])\n",
      "y shape torch.Size([284, 3])\n"
     ]
    }
   ],
   "source": [
    "y = labels[:, :3] # choose teff, log, feh\n",
    "print(y.shape)\n",
    "\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 3)\n",
    "print(y.shape)\n",
    "\n",
    "x = spectra[:,:10]\n",
    "\n",
    "print('x shape', x.shape) #choose all the conditions\n",
    "print('y shape', y.shape) #choose the first three labels to condition on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> start the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose prior here\n",
    "dim = x.shape[-1]\n",
    "cond_dim = y.shape[-1]\n",
    "\n",
    "base_mu, base_cov = torch.zeros(dim).to(device), torch.eye(dim).to(device)\n",
    "prior = MultivariateNormal(base_mu, base_cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the normalising flow\n",
    "nfs_flow = NSF_CL\n",
    "flows = [nfs_flow(dim=dim, context_features=cond_dim, K=8, B=3, hidden_dim=128) for _ in range(5)]\n",
    "convs = [Invertible1x1Conv(dim=dim) for _ in flows]\n",
    "norms = [ActNorm(dim=dim) for _ in flows]\n",
    "flows = list(itertools.chain(*zip(norms, convs, flows)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the model\n",
    "model = NormalizingFlowModel(prior, flows).to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-6, weight_decay=0)  # todo tune WD\n",
    "print(\"number of params: \", sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "# train_loader\n",
    "dataset = TensorDataset(x, y)\n",
    "\n",
    "# Create a data loader from the dataset\n",
    "# Type of sampling and batch size are specified at this step\n",
    "loader = DataLoader(dataset, batch_size=71, shuffle=True, pin_memory=True) #this will give x, y per batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> the actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "print(\"Started training\")\n",
    "for k in range(20000):\n",
    "    for batch_idx, data_batch in enumerate(loader):\n",
    "        x, y = data_batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        zs, prior_logprob, log_det = model(x, context=y)\n",
    "        logprob = prior_logprob + log_det\n",
    "        loss = -torch.sum(logprob)  # NLL\n",
    "\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if k % 100 == 0:\n",
    "        print(\"Loss at step k =\", str(k) + \":\", loss.item())\n",
    "    \n",
    "path = f\"test_model.pth\"\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = np.ones((300, 3))\n",
    "cont[:, 0] = y[0][0]\n",
    "cont[:, 1] = y[0][1]\n",
    "cont[:, 2] = y[0][2]\n",
    "cont = torch.tensor(cont, dtype=torch.float32).reshape(-1, 3)\n",
    "\n",
    "zs = model.sample([300], context=cont)\n",
    "z = zs[-1]\n",
    "z = z.to('cpu')\n",
    "z = z.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f'test_model.pth'\n",
    "state_dict = torch.load(fname)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NormalizingFlowModel(prior, flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NormalizingFlowModel(\n",
       "  (flow): NormalizingFlow(\n",
       "    (flows): ModuleList(\n",
       "      (0): ActNorm()\n",
       "      (1): Invertible1x1Conv()\n",
       "      (2): NSF_CL(\n",
       "        (f1): MLP(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.2)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.2)\n",
       "            (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2)\n",
       "            (6): Linear(in_features=128, out_features=115, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (f2): MLP(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.2)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.2)\n",
       "            (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2)\n",
       "            (6): Linear(in_features=128, out_features=115, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (g1): MLP(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.2)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.2)\n",
       "            (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2)\n",
       "            (6): Linear(in_features=128, out_features=115, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (g2): MLP(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.2)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.2)\n",
       "            (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2)\n",
       "            (6): Linear(in_features=128, out_features=115, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ActNorm()\n",
       "      (4): Invertible1x1Conv()\n",
       "      (5): NSF_CL(\n",
       "        (f1): MLP(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.2)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.2)\n",
       "            (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2)\n",
       "            (6): Linear(in_features=128, out_features=115, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (f2): MLP(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.2)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.2)\n",
       "            (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2)\n",
       "            (6): Linear(in_features=128, out_features=115, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (g1): MLP(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.2)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.2)\n",
       "            (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2)\n",
       "            (6): Linear(in_features=128, out_features=115, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (g2): MLP(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.2)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.2)\n",
       "            (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2)\n",
       "            (6): Linear(in_features=128, out_features=115, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): ActNorm()\n",
       "      (7): Invertible1x1Conv()\n",
       "      (8): NSF_CL(\n",
       "        (f1): MLP(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.2)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.2)\n",
       "            (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2)\n",
       "            (6): Linear(in_features=128, out_features=115, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (f2): MLP(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.2)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.2)\n",
       "            (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2)\n",
       "            (6): Linear(in_features=128, out_features=115, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (g1): MLP(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.2)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.2)\n",
       "            (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2)\n",
       "            (6): Linear(in_features=128, out_features=115, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (g2): MLP(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.2)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.2)\n",
       "            (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2)\n",
       "            (6): Linear(in_features=128, out_features=115, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): ActNorm()\n",
       "      (10): Invertible1x1Conv()\n",
       "      (11): NSF_CL(\n",
       "        (f1): MLP(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.2)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.2)\n",
       "            (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2)\n",
       "            (6): Linear(in_features=128, out_features=115, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (f2): MLP(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.2)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.2)\n",
       "            (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2)\n",
       "            (6): Linear(in_features=128, out_features=115, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (g1): MLP(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.2)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.2)\n",
       "            (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2)\n",
       "            (6): Linear(in_features=128, out_features=115, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (g2): MLP(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.2)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.2)\n",
       "            (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2)\n",
       "            (6): Linear(in_features=128, out_features=115, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): ActNorm()\n",
       "      (13): Invertible1x1Conv()\n",
       "      (14): NSF_CL(\n",
       "        (f1): MLP(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.2)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.2)\n",
       "            (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2)\n",
       "            (6): Linear(in_features=128, out_features=115, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (f2): MLP(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.2)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.2)\n",
       "            (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2)\n",
       "            (6): Linear(in_features=128, out_features=115, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (g1): MLP(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.2)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.2)\n",
       "            (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2)\n",
       "            (6): Linear(in_features=128, out_features=115, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (g2): MLP(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "            (1): LeakyReLU(negative_slope=0.2)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): LeakyReLU(negative_slope=0.2)\n",
       "            (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (5): LeakyReLU(negative_slope=0.2)\n",
       "            (6): Linear(in_features=128, out_features=115, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (_embedding_net): Identity()\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = np.ones((300, 3))\n",
    "cont[:, 0] = y[0][0]\n",
    "cont[:, 1] = y[0][1]\n",
    "cont[:, 2] = y[0][2]\n",
    "cont = torch.tensor(cont, dtype=torch.float32).reshape(-1, 3)\n",
    "\n",
    "zs = model.sample([300], context=cont)\n",
    "z = zs[-1]\n",
    "z = z.to('cpu')\n",
    "z = z.detach().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0531175 , 0.98051447, 1.0748194 , ..., 0.6227579 , 1.1264045 ,\n",
       "        0.7954603 ],\n",
       "       [1.0398533 , 1.0208899 , 1.0808082 , ..., 0.769331  , 1.1143516 ,\n",
       "        0.89089245],\n",
       "       [1.0489525 , 0.97699344, 1.0360457 , ..., 0.56318367, 1.0298252 ,\n",
       "        0.9020064 ],\n",
       "       ...,\n",
       "       [1.0420896 , 0.9865067 , 1.0371429 , ..., 0.71006024, 1.2230097 ,\n",
       "        0.8171582 ],\n",
       "       [1.0254723 , 1.0084943 , 1.0179685 , ..., 0.81573486, 1.1886083 ,\n",
       "        0.7591804 ],\n",
       "       [1.0421239 , 0.98651856, 1.0371597 , ..., 0.7100506 , 1.2232546 ,\n",
       "        0.81725633]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
